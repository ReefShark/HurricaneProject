---
title: "Hurricane Report"
author: "Jerry Chen and Jocelyn Hunyadi"
date: "12/4/2017"
output:
  pdf_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r, echo = FALSE}
# Acquire Necessary R Packages:
require(devtools)
require(RCurl)
require(httr)
require("gganimate")
require(ggmap)
require(stringr)
require(mdsr)
require(tidyverse)
require(mosaic)
require(tidyr)
require(dplyr)
require(readxl)
require(rvest)
require(lubridate)

# Working directory should be the repo folder - add data to the repo folder

```

# Abstract

In the aftermath of the destruction caused by hurricane Harvey, many environmentalists and climate change specialists have suggested a link between global warming and the impact of tropical storms. Since 1980, and perhaps before then, atmospheric co2 levels have increased steadily each year. The goals of this report are, first, to determine if there is a significant relationship between increasing atmospheric co2 levels and hurricane damage and, second, to visually analyze the path of costly hurricanes. After adjusting for inflation, our analyses indicate that co2 is significantly correlated with an increase in total economic damage per Atlantic hurricane season. Additionally, the paths of 9 of the most costly hurricanes do not suggest a specific path for highly damaging hurricanes, but reveal some interesting deviations from the general path shape.

# Introduction
  
The 2017 Atlantic hurricane season incurred 367.5 Billion USD in economic costs from hurricane damage along the coast and interior of the USA. It produced two incredibly costly hurricanes: Harvey and Maria. In light of these particularly destructive hurricanes, discussion of the impacts of climate change has increased and shifted to focus on the specific impacts of tropical storms. This report hopes to participate in this discussion. More specifically, using linear models, we will determine whether or not increasing annual average atmospheric co2 (ppm) is correlated with increasing hurricane damage. Additionally, using the `gganimate` package in R, we will perform a visual analysis of the path of some of the most destructive, costly Atlantic hurricanes. 

If, in fact, increasing co2 is a significant, positively correlated predictor to hurricane damage, then our models may be able to predict the future expected damage by Atlantic hurricanes, should atmospheric co2 continue to rise. Using these predicted estimates, further evidence can be presented on why addressing climate change concerns are important. Furthermore, if some of the more destructive hurricanes follow a specific path, it may be possible to better prepare or defend these areas from incoming severe weather attributed to tropical storms. 

This report first attempts to fit a handful of models with atmospheric co2 as the predictor of a variety of hurrican damage metrics including the average damage per season incurred by costly hurricanes, the maximum damage per season incurred by a costly hurricane, and the total damage incurred per hurricane season by all hurricanes. Using each of our models, prediction intervals will be generated for predicing the damage by Harvey as well as the total damage for the 2017 Hurricane season. Since the estimated damage was not finalized for Maria at the time of this report, Harvey is considered the most costly Atlantic hurricane of the 2017 season. Finally, by generating a variety of gifs, we will simulate the paths and overlap of 9 costly Atlantic hurricanes, should they have occurred all in the same season.

# Data

## Datasets:

To explore the relationship between gobal warming and the impact of tropical cyclones, we obtained 4 datasets. The first dataset, `CO2_data`, contains the average level of global atmospheric co2 (ppm) for each year from 1980 to 2016. The data was originally obtained as a txt file from the National Oceanographic and Atmostpheric Administration (NOAA). The average global atmospheric co2 for 2017 was also obtained from the NOAA official website. 

The second dataset, `costly_hurr`, includes Atlantic hurricanes that incurred $1 Billion or more in damage to the United States. The original dataset, scraped from Wikipedia, included the following variables: Name (of the hurricane), Damage (in Billions), Storm Classification (at peak intensity), Areas Affected, and References. Peak hurricane category was extracted from the storm classification variable. Additionally, the `CO2_data` dataset was joined to this dataset for analysis by the year.

The third dataset, `seasons_hurr`, includes the total amount of damage costs for each Atlantic hurricane season from 1980 to 2016. This dataset, like the previous, was scraped from Wikipedia and includes the following variables for each year: the number of tropical storms, the number of hurricanes, the number of major hurricanes (Category 3-5), deaths, and damage. Additionally, the `CO2_data` dataset was also joined to this dataset by the year for analysis.

The final dataset is a compilation of hurricane path and damage data for 9 costly Atlantic hurricanes obtained from NOAA in addition to census data by county from the US Census Bureau website. The 9 hurricanes selected are among the Top 11 most costly Atlantic Hurricanes and include: Katrina, Sandy, Ike, Wilma, Ivan, Irene, Charley, Matthew, and Rita. The most costly Atlantic hurricane, Harvey (2017), was not included because data is currently unavailable. Additionally, data for Andrew (1992), the 6th most costly Atlantic hurricane, was limited in comparison to the other hurricanes. Rather than spending additional time wrangling the data for Andrew, we chose to include hurricane Rita instead. The `hurr_9` dataset includes the following variables for each hurricane at each date and time where it was a tropical storm: latitude, longitutde, wind speed (kts), stage, landfall, county, state abbreviation, property damage, crop damage, damage total, timezone, year, population, and category. 

```{r, echo = FALSE}
# Obtain CO2 Data - Found originally in txt file:
CO2_data <- read.csv("CO2_data.csv")
  # Remove excess Column:
CO2_data <- CO2_data[,2:3]
  # Correct column names according to tidy:
colnames(CO2_data) <- c("year","co2")
```

```{r, echo = FALSE}
# Scrape the Data for the Costliest Atlantic Hurricanes from Wikipedia:
url <- 'https://en.wikipedia.org/wiki/List_of_costliest_Atlantic_hurricanes'
list <- url %>%
  read_html() %>%
  html_nodes("table")
  
  # Select the correct table to a dataframe:
costly_hurr <- html_table(list[[1]], fill = TRUE)

  # Join with CO2 Data:
costly_hurr <- left_join(costly_hurr, CO2_data, by = c("Season" = "year"))

  # Modify column names:
colnames(costly_hurr) = c("name","damage","year","classification","area","reference","co2")

# Save Harvey Damage (for later use):
actual_Harvey <- readr::parse_number(substring(costly_hurr$damage[1],2))

# Modifications to the Data:
  # Remove entries with NA in co2 column:
costly_hurr <- costly_hurr %>% filter(!is.na(co2)) %>%
  # Extract numbers from damage column and convert to numeric:
  mutate(damage = readr::parse_number(substring(damage,2)))

  # Remove part of string excess from classification column:
costly_hurr <- costly_hurr %>%
  mutate(classification = substring(classification,12))

  # Add Category variable
costly_hurr <- costly_hurr %>%
  mutate(category = ifelse(classification == "storm", 0, substring(classification,2,2))) %>%
  mutate(category = ifelse(category == "s", 0, readr::parse_number(category))) %>%
  mutate(category_factor = as.factor(category))

```

```{r, echo = FALSE}
# Scrape the Data for each Atlantic Hurricane Season since 1980:
  # Data originally obtained from the following url:
  # https://en.wikipedia.org/wiki/Atlantic_hurricane_season#Number_of_tropical_storms_and_hurricanes_per_season
  # Data was Modified - modified data = Hurricane_Seasons.csv
  # Please See the Appendix to see how data was modified
seasons_hurr <- read_csv("Hurricane_Seasons.csv")
seasons_hurr <- seasons_hurr[,2:10]

  # Join to CO2 Data:
seasons_hurr <- left_join(seasons_hurr, CO2_data, by = c("year" = "year"))
current_season <- seasons_hurr$damage[38]
```

```{r, echo = FALSE}
# Load in Compilation Dataset of Hurricane Path, Damage, and Census Data for the 9 Costly Hurricanes:
hurr_9 <- read_csv("Costly_9_Data.csv")

```

## Univariate Analysis:

Prior to conducting our analysis, we briefly verified the relationship between year and atmospheric co2. As expected, there is a strong, positive relationship between the two variables. Alternatively put, since 1980, Atmospheric co2 has steadily increased to a present value slightly above 400 ppm. 

```{r, echo = FALSE}
# CO2:
ggplot(CO2_data, aes(x = year, y = co2)) + geom_point() + labs(title = "Change in Atmospheric CO2 since 1980", x = "Year", y = "CO2 (ppm)")
```



# Results

## Linear Regression Model for Average Damage by Costly Atlantic Hurricanes each Season:

To determine if annual average atmospheric co2 (ppm) is postively correlated with the estimated economic cost of damage by hurricanes, we fit a series of linear models. If co2 is positively correlated, the estimated coefficient for co2 should be positive and the p-value associated with co2 should be significant (P-value < .05).

```{r, echo = FALSE}
# Looking at AVERAGE damage for hurricanes that occurred in the same year:
costly_hurr_2 <- costly_hurr %>%
  group_by(co2) %>%
  summarise(avg_damage = mean(damage), total_damage = sum(damage), max_damage = max(damage)) %>%
  mutate(sqrt_avg_damage = sqrt(avg_damage), sqrt_max_damage = sqrt(max_damage))

# Plot:
ggplot(costly_hurr_2, aes(y = sqrt_avg_damage, x = co2)) + geom_point() + labs(title = "Average Damage by Costly Hurricanes", x = "CO2 (ppm)", y = "Square Root Average Damage (Billions)") + geom_smooth(method = "lm")

# Fit the model:
mod_avg <- lm(sqrt_avg_damage ~ co2, data = costly_hurr_2)
summary(mod_avg)

```

Some hurricane seasons in our dataset contained only 1 costly hurricane while others had more than 1 costly hurricane. Our first model addressed the average damage caused by costly hurricanes each season. With `avg_damage` as the response variable, co2 was not a significant predictor. However, when the square root of `damage` was used as the response variable, co2 was a significant predictor (P-value < .05). The model estimates that for every  1 ppm increase in atmospheric co2, the square root of average damage by Atlantic costly hurricanes will increase by .03365 billion USD This model appears to suggest that increasing co2 is correlated with an increase in hurricane impact, specifically in the damage caused. However, the model only accounts for 16.44% of the variation in the square root of average damage. 


## Linear Regression Model for Maximum Damage by Costly Atlantic Hurricanes each Season:

```{r, echo = FALSE}
# Plot:
ggplot(costly_hurr_2, aes(y = sqrt_max_damage, x = co2)) + geom_point() + labs(title = "Damage by the Most Costly Hurricane", x = "CO2 (ppm)", y = "Sqare Root Max Damage (Billions)") + geom_smooth(method = "lm")

# Modeling MAX damage for costly hurricanes:
mod_max <- lm(sqrt_max_damage ~ co2, data = costly_hurr_2)
summary(mod_max)
```

For the next model, the maximum damage caused by a costly hurricane each season was considered for the response. Once again, with `max_damage` as the response variable, co2 was not a significant predictor. When the square root of `max_damage` was used as the response variable, co2 was a significant predictor (P-value < .05). The model estimates that for every 1 ppm increase in atmospheric co2, the square root of maximum damage by Atlantic costly hurricanes will increase by an estimated .055 billion USD This model also appears to suggest that increasing damage is correlated with increasing atmospheric co2. However, once again, the model only accounts for 16.4% of the variation in the square root of maximum damage.


## Linear Regression Model for Total Damage for each Atlantic Hurricane Season 1980-2016:

```{r, echo = FALSE}
# Hurricane Season:
seasons_hurr <- seasons_hurr %>%
  filter(!is.na(co2)) %>%
  mutate(log_damage = log(damage))

# Plot:
ggplot(seasons_hurr, aes(x = co2, y = log_damage)) + geom_point() + labs(title = "Damage per Hurricane Season 1980 - 2016", x = "CO2 (ppm)", y = "Log Damage") + geom_smooth(method = "lm")

  # Model with co2 as sole predictor:
season_mod1 <- lm(log_damage ~ co2, data = seasons_hurr)
summary(season_mod1) # Sig at .05, R = .13

```

The next response variable considered was the total damage caused by all hurricanes for each Atlantic hurricane season from 1980 to 2016. The damage estimates from this dataset are expressed in contemporaneous US dollars. With `damage` as the response variable, co2 was not a significant predictor, as expected based on the previous two models. However, when `log_damage` was the response variable, co2 was a significant predictor (P-value < .05). The model estimates that for ever 1 ppm increase in annual average atmospheric co2, the estimated log damage will increase by .04401 Billion USD. In other words, the model appears to suggest that increasing atmospheric co2 is correlated with increasing damage by hurricanes. However, this model only accounts for 13.92% of the variation in `log_damage`.
 


# Diagnostics

## Models and Predictions for 2017:

The models and associated scatterplots in the results section indicate that there is a relationship between increasing co2 and rising costs of damage caused by Atlantic hurricanes. However, all three models have low R-squared values (<.2) and thus, may have limited or no predictive power. To test the predictive power of our models, we attempted to predict the costs of damage associated with hurricane Harvey, the costliest hurricane for the 2017 season at the time of this analysis, and the total damage costs for the 2017 Atlantic hurricane season. While the annual average atmospheric co2 measurement is not available, monthly measurements are available. The November average atmospheric co2 measurement (approximately 403 ppm) was used for the predictions.

### 95% Prediction Interval for Average Damage model:
```{r, echo = FALSE}
# Predicting Harvey Damage from Average:
newdata <- data.frame(co2 = 403.38)
  # Must square - y = sqrt_damage:
p1 <- (predict(mod_avg, newdata, interval = "predict"))^2; p1
  # Difference with Upper:
avg_upper_diff <- actual_Harvey - p1[3]; avg_upper_diff # off by 152 billion
  # Difference with Lower:
avg_lower_diff <- actual_Harvey - p1[2]; avg_lower_diff # off by 198.3037 billion
  # Not Very Useful. Also, doesn't quite make as much sense to use the Average.

```

### 95% Prediction Interval for the Max Damage model:
```{r, echo = FALSE}
# Predicting Harvey Damage from Maximum:
p2 <-(predict(mod_max, newdata, interval = "predict"))^2; p2
  # Difference with Upper:
max_upper_diff <- actual_Harvey - p2[3]; max_upper_diff # off by 94.6 billion
  # Difference with Lower:
max_lower_diff <- actual_Harvey - p2[2]; max_lower_diff # off by 198 billion
  # Actual Fit:
max_actual_diff <- actual_Harvey - p2[1]; max_actual_diff # off by 173.28 billion
  # Better, but still off by a lot.
  
  # Lurking Variables may account for unaccounted for variation in damage.
```

The accepted damage by hurricane Harvey is 198.63 Billion USD. The average damage by costly hurricanes model predicted an estimated damage cost of 25.35 Billion USD with a lower bound of 16 Million USD and an upper bound of 104 Billion USD. This interval does not encompass the actual damage costs of hurricane Harvey. However, since we are interested in predicing the cost of one hurricane, the Max Damage by costly hurricanes model may provide a better fit. However, this model actually does worse. It predicted an estimated damage cost of 13.67 Billion USD with a lower bound of 326 Million USDs and an upper bound of only 46 Billion USD. Thus, as suspected, the predictive power of these two models does appear to be limited. 

### 95% Prediction Interval for the Season Model:
```{r, echo = FALSE}
# Predicting 2017 Hurricane Season Damage:
p3 <- exp(predict(season_mod1, newdata, interval = "predict")); p3
  # Difference with upper:
season_upper_diff <- current_season - p3[3]; season_upper_diff # Over Predicted.
  # Difference with lower:
season_lower_diff <- current_season - p3[2]; season_lower_diff # Under Predicted
  # Difference with Fit:
season_actual_diff <- current_season - p3[1]; season_actual_diff # Under Predicted
```

The accepted damage for the 2017 hurricane season is 367.5 Billion USD. Using the November monthly average co2 measurement, the hurricane season model predicted an estimated damage cost of 9.802 Billion USD with a lower bound of 106 Million USD and an upper bound of 904 Billion USD. The prediction interval generated from this model, unlike the pervious, does contained the actual accepted damage for the 2017 season. However, it is important to note that this prediction interval is very broad. 


## Hurricane Path:

In addition to the correlation and prediction analyses of the hurricane strength, co2 levels, and hurricane damage discussed above, another major goal of our project was to be able to dynamically animate the hurricanes used in our analyses using the `gganimate` package, something that went beyond the scope of the material taught in class.

Initially, we envisioned an animation that not only displayed the path of the hurricane, but showed the damage of the hurricane as it progressed through the continental US in the form of a heatmap. While we did have damage and death data at the county level at specific time intervals that coincided with our path (latitude & longitude) data, when we summed up the damage figures and compared with figures that news outlets reported, it became apparent that the data we had was unreliable. For some hurricanes, the summed values were much higher than the numbers presented by news outlets, and for others, the summed values were much lower. As a result, we decided to remove the damage component of the animation and focus on the path component.

The data used for the path animations came from the `Costly_9_Data`, described earlier in the report. Below is the code used to wrangle the data provided in this dataset to match the aesthetics of the `gganimate` function. In particular, the date_time column was created by combining the time and date values for each observation. Each of these date_time values served as the frame marker for the animation, with the time between intervals being 6 hours, same as presented in the original NOAA dataset.

## Data Wrangling for Animations
```{r, warning = FALSE, eval = FALSE}
# Read in data
Costly_9_Data <- read_csv("Costly_9_Data.csv")

Path_All <- Costly_9_Data
names(Path_All)[4:5] = c("latitude", "longitude")
Path_All <- Path_All %>%
  select(date, time, name, latitude, longitude, `wind(kts)`, category) %>%
  unique() %>%
  filter(!is.na(latitude), !is.na(longitude), !is.na(`wind(kts)`)) %>% #removing missing data
  mutate(isHurricane = ifelse(is.na(category), FALSE, #creating the isHurricane designation
                              ifelse(category > 0, TRUE, FALSE)),
         longitude = -1*longitude, #negating longitude to match the latitude/longitude designation that Google Maps uses
         time_long = ifelse(time == 0, "00:00:00",  #converting from military time
                            ifelse(time == 600, "06:00:00",
                                   ifelse(time == 1200, "12:00:00", "18:00:00"))),
         date_time = ymd_hms(paste(as.character(date), time_long), tz = "US/Eastern"))
```

The code below looped through all the hurricanes we had path data for and produced individual animations, outputted in GIF format. The map background for the animations was pulled from Google Maps and the frame of the background adjusted to best capture the entirety of each of the individual hurricane paths. In addition to outlining the path of the hurricane, the size of the hurricane symbol adjusted to correspond with the wind speed. The symbol also changed colors depending on the classification of the hurricane at each frame. A blue symbol corresponded to a tropical storm or tropical depression, while a red symbol corresponded with to an actual hurricane, with hurricane-force winds. These 9 individual hurricane path animations were written into the working directory.

## Creating Individual Hurricane Animations
```{r, warning = FALSE, eval = FALSE}
hurricanes = unique(Path_All$name)

# for loop that iterates through the 9 hurricanes
for (i in 1:9) {
  hurricane_name = hurricanes[i]
  Hurricane_path <- Path_All %>%
    filter(name == hurricane_name, !is.na(latitude), !is.na(longitude), !is.na(`wind(kts)`)) %>%
    arrange(date_time)
  
  map_bbox <- make_bbox(lat = latitude, lon = longitude, data = Hurricane_path) #specify bounds of map
  m <- get_map(location = c(lon = mean(Hurricane_path$longitude), lat = mean(Hurricane_path$latitude)), source = "google", maptype = "terrain", zoom = 4) #create map
  
  p <- ggmap(m) + 
    geom_path(aes(x=longitude, y=latitude, cumulative = TRUE, frame = date_time), data=Hurricane_path) +
    geom_point(aes(x=longitude, y=latitude, size = `wind(kts)`, frame = date_time, color = isHurricane), shape = 8, data=Hurricane_path) + 
    scale_color_manual(values=c("slateblue4", "firebrick3")) #setting the colors to red and blue for the hurricane designation in the animation

  file_location = paste(hurricane_name, ".gif", sep = "")
  gganimate(p, filename=file_location)
}
```

We additionally wanted to combine all these hurricanes into one animation in an attempt to analyze the paths and timing of these 9 costly hurricanes. This was done by imposing all 9 of the hurricanes onto one year (2017), as if all of these hurricanes occurred in the same hurricane season. The resulting animation revealed some interesting trends, but nothing that stood out in particular with regards to the hurricane path and hurricane timing. Generally, with the exception of Hurricane Sandy, all the hurricanes began in a northwesterly direction and veered past the continental US in a northeasterly direction. Hurricane Sandy did the opposite, heading northeasterly along the US East Coast initially, before abrubtly veering west, making landfall around New York. Although some hurricanes struck at the same time, there was a generally even spacing of the hurricanes. Sandy was the latest of these hurricanes, which may explain why the path of Sandy differed from the rest.  

## Combined GIF: All Hurricanes
```{r, eval = FALSE}
All = Path_All
year(All$date) = 2017 #setting all the years to 2017
All$date_time = ymd_hms(paste(as.character(All$date), All$time_long), tz = "US/Eastern") #creating the frame for the animation

m <- get_map(location = c(lon = mean(Path_All$longitude), lat = mean(All$latitude)), source = "google", maptype = "terrain", zoom = 4) #create map

p <- ggmap(m) + 
  geom_path(aes(x=longitude, y=latitude, cumulative = TRUE, frame = date_time, color = name), data=All) +
  geom_point(aes(x=longitude, y=latitude, size = `wind(kts)`, frame = date_time, color = name), shape = 8, data=All)

gganimate(p, interval = .3, filename="combined.gif")
```

# Conclusion

The first goal of this investigation was to determine if there was any correlation between increasing atmospheric co2 (ppm) and increasing economic costs of damage associated with Atlantic hurricanes. The three linear models generated suggest that there is a positive, significant relationship between co2 and damage by hurricanes. In addition, the model for hurricane season damage produced a prediction interval that did contain the actual damage for the 2017 Atlantic hurricane season. 

However, it is important to note that the first two models failed to predict the damage caused by hurricane Harvey. This failure may be due, in part, to the unadjusted damage values. Although the hurricane season model contained damage values adjusted for inflation, the average and max damage by costly hurricanes models did not contain adjusted damage values. Therefore, the these two models may be improved by adjusted the damage values for inflation.

The models could be further improved by including a variable for the hurricanes damage potential. In other words, based on the path, known for older hurricanes and predicted for new ones, how much damage could the hurricane potentially cause? One factor in damage potential is the population affected. For example, consder two hurricanes with the same strength. If the first hurricane primarily encounters rural areas, its potential for damage is reduced. If the second hurricane encounters a higher concentration of urban or industrial areas, its potential for damage would be increased since more homes, industry, infrastructure, and other buildings could be destroyed. Accounting for this lurking variable may improve the predictive power of our models and may even suggest an even greater association between atmospheric co2 and hurricane damage.

The generation of the path animations was a general success, given the aforementioned damage/deaths data limitations. The animation of the paths were successfully completed for all 9 hurricanes that we had data for. While the animations showed no general trend in the paths and timing of these costly hurricanes, a mathematical approach to assessing the similarility of paths would be an interesting next step. Our animation analysis was also only focused on the 9 costly hurricanes of the past two decades or so. While the incorporation of more hurricanes would be useful in analyzing path trends, the animation itself may become too cluttered and become a hairball of sorts, which may not serve us much use. Therefore, a mathematical approach to assessing the similarity of paths, in addition to a more concise version of the animation with more hurricanes, would also be a good next step.



# Appendix

### Modifications to Hurricane Season Data:
```{r, eval = FALSE}
url <- "https://en.wikipedia.org/wiki/Atlantic_hurricane_season#Number_of_tropical_storms_and_hurricanes_per_season"

list <- url %>%
  read_html() %>%
  html_nodes("table")
  
# Get Data:
names <- c("year","num_trop_storms","num_hurricanes","num_major","deaths","damage")

h_season08 <- html_table(list[[15]], fill = TRUE)
h_season08 <- h_season08[,c(1,3:7)]
colnames(h_season08) <- names

h_season09 <- html_table(list[[16]], fill = TRUE)
h_season09 <- h_season09[,c(1,3:7)]
colnames(h_season09) <- names

h_season10 <- html_table(list[[17]], fill = TRUE)
h_season10 <- h_season10[,c(1,3:7)]
colnames(h_season10) <- names

h_season11 <- html_table(list[[18]], fill = TRUE)
h_season11 <- h_season11[,c(1,3:7)]
colnames(h_season11) <- names

# Join together:
h_season <- rbind(h_season08, h_season09, h_season10, h_season11)

# Remove entries with Unknown damage:
h_season <- h_season %>% filter(damage != "Unknown")

# Remove symbols/words from Damage and multiply by appropriate multiplier column:
h_season <- h_season %>%
  mutate(damage_number = readr::parse_number(str_extract(damage, "[0-9|\\.]+")),
         damage_magnitude = str_extract(damage, "[m|b]illion"),
         damage_magnitude = ifelse(is.na(damage_magnitude), "thousand", damage_magnitude),
         damage = ifelse(damage_magnitude == "thousand", damage_number*1000, 
                         ifelse(damage_magnitude == "million", damage_number*1000000, damage_number*1000000000)))

# Add total storms column:
h_season <- h_season %>% mutate(storms_total = num_trop_storms + num_hurricanes)
```

### Process of Acquiring Path, Damage, and Population Data for the 9 Hurricanes:

Path Data for each Hurricane (listed in the Data section) was contained in a table on a hurricane's report on the NOAA website. PDFtables.com converted the pdf file to an excel file for use. The following code was used for all 9 of the hurricanes, but hurricane Rita will be used as an example.

#### Initial Loading of Path Data:
```{r, eval = FALSE}
# Note: All files were saved in the working directory for this portion:

# Load in the Excel File:
Rita <- read_excel("Rita.xlsx", sheet = 11)

# Temporarily Store certain information:
datelandfall1 <- "24 / 0740"
landfall1 <- "Johnson's Bayou, LA"
  # Note: For Hurricanes with more than one date and location of landfall, there was more than 1 datelandfall and landfall holder

# Remove Extra Rows and Columns:
Rita <- Rita[c(4:38,42),] 
  # The excel files contained extra, misc. information that was unneded
  # Rows selected varied by hurricane

# Change some column names:
name <- c("Date_Time","Latitude(N)","Longitude(W)","Pressure","Wind(kts)","Stage")
colnames(Rita) <- name

```

#### Path Data Clean-up:
```{r, eval = FALSE}
  # Edit Data:
Rita <- Rita %>%
  mutate(Landfall = ifelse(Date_Time == datelandfall1, landfall1, "No"))

# Seperation of Date_Time into Date and Time:
Rita <- Rita %>%
  # Extract individual variables from Date_Time
  mutate(Year = "2005", 
         Time = substring(Date_Time,5,9),
         Day = substring(Date_Time,1,2),
         Month = "9") %>%
  # Join Year, Month, and Day together:
  unite(Date, Year, Month, Day, sep = "-", remove = FALSE) %>%
  # Change Date to Date format:
  mutate(Date = as.Date(Date)) %>%
  select(Date, Time, `Latitude(N)`, `Longitude(W)`, Pressure, `Wind(kts)`, Stage, Landfall)

# Convert Some Columns to Numeric:
Rita <- Rita %>%
  mutate(Time = readr::parse_number(Time),
         `Wind(kts)` = readr::parse_number(`Wind(kts)`),
         `Latitude(N)` = readr::parse_number(`Latitude(N)`),
         `Longitude(W)` = readr::parse_number(`Longitude(W)`))
  
# Obtain the Category Level from Wind Speed:
Rita <- Rita %>%
  mutate(Category = ifelse(`Wind(kts)` < 64, 0, ifelse(`Wind(kts)` >= 62 & `Wind(kts)` <= 82,1,ifelse(`Wind(kts)` >= 83 & `Wind(kts)` <= 95,2,ifelse(`Wind(kts)` >= 96 & `Wind(kts)` <= 113,3,ifelse(`Wind(kts)` >= 114 & `Wind(kts)` <= 135, 4,5))))))
```

The NOAA website has an option to search damage records by text search. Using this method, it is possible to search for specific hurricanes. However, the data provided is not downloadable. It is possible to also search by date and state and obtain data downloadable as a csv. Using the dates of each hurricane and the states known to be affected, damage data was gathered using this method. Once damage data was obtained, it was joined to the path data by date and time. Below is the code for hurricane Rita: 

#### Acquire Damage Data and Cleanup:
```{r, eval = FALSE}
# Example of Loading in a csv file for a state affected by Hurricane Rita:
RitaFlorida <- read_csv("RitaFlorida.csv")

# Bind all Damage Data Together:
RitaDamage <- rbind(RitaPuerto, RitaFlorida, RitaTexas, RitaLouis, RitaMiss, RitaArkansas, RitaTenn, RitaMissouri)

# Change BEGIN_DATE to a Date type:
RitaDamage <- RitaDamage %>%
  mutate(BEGIN_DATE = mdy(BEGIN_DATE))

# Change Time to 0, 600, 1200, 1800 - Based on a determined Range:
  # 0 - 600 --> 0, 600 - 1200 --> 600, 1200 - 1800 --> 1200, 1800
  # Ensures every damage point will match to the Hurricane Data
  # Hurricane data typically only recorded at 0, 600, 1200, 1800
RitaDamage <- RitaDamage %>%
  mutate(BEGIN_TIME = ifelse(BEGIN_TIME >= 0 & BEGIN_TIME < 600, 0, 
                       ifelse(BEGIN_TIME >= 600 & BEGIN_TIME < 1200, 600,
                              ifelse(BEGIN_TIME >= 1200 & BEGIN_TIME < 1800, 1200,
                                     1800))))

```

#### Join Path and Damage Data:
```{r, eval = FALSE}
# Join the Data on Date and Time:
RitaCombined <- left_join(Rita, RitaDamage, by = c("Date" = "BEGIN_DATE", "Time" = "BEGIN_TIME"))

# Total Damage Column:
RitaCombined <- RitaCombined %>% 
  mutate(DAMAGE_TOTAL = DAMAGE_PROPERTY_NUM + DAMAGE_CROPS_NUM)

# Remove NAs from Total Damage:
RitaCombined1 <- RitaCombined %>% filter(!is.na(DAMAGE_TOTAL))
RitaCombined1 <- RitaCombined1 %>% filter(DAMAGE_TOTAL >= 0)

# To ensure the results of this process were not lost, the data was written to a csv file at this time.
write.csv(RitaCombined1, "RitaCombinedData.csv")
```

Census data was downloaded from the US Census Bureau website as two csv files: 1 for 2010-2016 and another for 2000-2010. Below is the process for obtaining census data:

#### Census Data 1: 2010-2016
```{r, eval = FALSE}
# Vector of correct column names:
names <- c("id","id2", "geography", "2010_census","2010_estimate_base","2010_estimate_july","2011","2012","2013","2014","2015","2016")

# Load in the Data:
USA <- read_csv("CensusData/USA1016.csv")
  # Change Column Names
colnames(USA) <- names
  # Remove Excess Row
USA <- USA[2:3143,]

# Seperate Geography into State and County:
USA <- USA %>%
  mutate(state = str_split_fixed(geography, ", ", 2)[,2],
         county = str_split_fixed(geography, ", ", 2)[,1])

# Change columns to numeric:
USA <- USA %>%
  mutate(`2010_census` = readr::parse_number(`2010_census`),
         `2010_estimate_base` = readr::parse_number(`2010_estimate_base`),
         `2010_estimate_july` = readr::parse_number(`2010_estimate_july`),
         `2011` = readr::parse_number(`2011`),
         `2012` = readr::parse_number(`2012`),
         `2013` = readr::parse_number(`2013`),
         `2014` = readr::parse_number(`2014`),
         `2015` = readr::parse_number(`2015`),
         `2016` = readr::parse_number(`2016`))

# Consolidate the 2010 columns into 1 average column:
USA <- USA %>%
  mutate(`2010` = trunc((`2010_census` + `2010_estimate_base` + `2010_estimate_july`)/3))

# Select Columns of importance:
USA <- USA %>% select(id, id2, state, county, `2010`, `2011`, `2012`, `2013`, `2014`, `2015`, `2016`)

# Convert to Tidy Format:
USA_tidy <- gather(USA, key = year, value = population, -id, -id2, -state, -county)

# Save the file for safety:
write.csv(USA_tidy, "USA2010_16_tidy.csv")
```

#### Census Data 2: 2000-2010
```{r, eval = FALSE}
# Vector of correct column names:
names <- c("lev","region","division","state_num","county_num","state","county","2000_base","2000_pop","2001","2002","2003","2004","2005","2006","2007","2008","2009","2010_census","2010_estimate")

# 2010 - 2016:
USA0 <- read_csv("CensusData/USA010.csv")
# Change Column Names:
colnames(USA0) <- names
  # Select only necessary columns:
USA0 <- USA0[,6:18]
  # Remove row for the entire state:
USA0 <- USA0 %>% filter(state != county)

# Consolidate 2000 columns into 1 average column:
USA0 <- USA0 %>%
  mutate(`2000` = (`2000_base` + `2000_pop`)/2)

# Select Columns:
USA0 <- USA0 %>% select(state, county, `2000`,`2001`,`2002`,`2003`,`2004`,`2005`,`2006`,`2007`,`2008`,`2009`)

# Convert to Tidy Format:
USA0_tidy <- gather(USA0, key = year, value = population, -state, -county)

# Write to file for safety:
write.csv(USA0_tidy, "USA2000_10_tidy.csv")
```

The Census data for 2010-2016 was joined to hurricanes that fell within those years. Similarly, the Census data for 2000-2010 was joined to the remaining hurricanes. Census data was joined to each of our 9 hurricanes. Once again, Rita will be used as the example in the code below:

#### Join Path, Damage, and Census Data:
```{r, eval = FALSE}
# Preparations to the Census Data before Joining:
# 2010-2016 Census Data:
USA_tidy <- read_csv("HurricaneData/USA2010_16_tidy.csv")
  # Remove District of Columbia:
USA_tidy <- USA_tidy %>%
  filter(state != "District of Columbia")
  # Convert state to Abbreviations to match path/damage data: 
for(i in 1:21987) {
  USA_tidy$state[i] = state.abb[grep(USA_tidy$state[i], state.name)]
  i = i + 1
}
  # Set county to lowercase to match path/damage:
USA_tidy <- USA_tidy %>%
  mutate(county = tolower(county))

# 2000-2010 Census Data:
USA0_tidy <- read_csv("HurricaneData/USA2000_10_tidy.csv")
  # Remove District of Columbia:
USA0_tidy <- USA0_tidy %>%
  filter(state != "District of Columbia")
  # Convert state to Abbreviations to match path/damage data:
for(i in 1:31420) {
  USA0_tidy$state[i] = state.abb[grep(USA0_tidy$state[i], state.name)]
  i = i + 1
}
  # Set county to lowercase to match path/damage:
USA0_tidy <- USA0_tidy %>%
  mutate(county = tolower(county))

# Join:
  # Load in if Saved previously or simply use RitaCombined
Rita <- read_csv("HurricaneData/RitaCombinedData.csv")

Rita <- Rita %>%
  mutate(CZ_NAME_STR = tolower(CZ_NAME_STR),
         Year = lubridate::year(Date)) %>%
  # Zones have NA in the BEGIN_LOCATION COLUMN:
  filter(!is.na(BEGIN_LOCATION)) %>%
  # Replace co. with county:
  mutate(CZ_NAME_STR = gsub("co\\.$","county",CZ_NAME_STR)) %>%
  # Remove entries with par. at the end:
  filter(!grepl("par\\.$",CZ_NAME_STR))
  # Combine with Census Data:
Rita_Census_tidy <- left_join(Rita, USA0_tidy, by = c("Year" = "year","CZ_NAME_STR" = "county","STATE_ABBR" = "state"))

# For safety - write to file:
write.csv(Rita_Census_tidy, "Rita_Census_tidy.csv")

```

#### Joining 9 Hurricanes Together:
```{r, eval = FALSE}
# Add Column for Hurricane Name:
Katrina_Census_tidy <- Katrina_Census_tidy %>% mutate(name = "Katrina")
Sandy_Census_tidy <- Sandy_Census_tidy %>% mutate(name = "Sandy")
Ike_Census_tidy <- Ike_Census_tidy %>% mutate(name = "Ike")
Wilma_Census_tidy <- Wilma_Census_tidy %>% mutate(name = "Wilma")
Ivan_Census_tidy <- Ivan_Census_tidy %>% mutate(name = "Ivan")
Irene_Census_tidy <- Irene_Census_tidy %>% mutate(name = "Irene")
Charley_Census_tidy <- Charley_Census_tidy %>% mutate(name = "Charley")
Matthew_Census_tidy <- Matthew_Census_tidy %>% mutate(name = "Matthew")
Rita_Census_tidy <- Rita_Census_tidy %>% mutate(name = "Rita")

# Remove Excess Columns that Remained:
Sandy_Census_tidy <- Sandy_Census_tidy[, c(1:46,49,50)]
Irene_Census_tidy <- Irene_Census_tidy[, c(1:46,49,50)]
Matthew_Census_tidy <- Matthew_Census_tidy[, c(1:46,49,50)]

# Bind together:
Costly_9_Data <- rbind(Katrina_Census_tidy, Sandy_Census_tidy, Ike_Census_tidy, Wilma_Census_tidy, Ivan_Census_tidy, Irene_Census_tidy, Charley_Census_tidy, Matthew_Census_tidy, Rita_Census_tidy) 

# Select Relevant Columns:
Costly_9_Data <- Costly_9_Data %>%
  select(Date, Time, `Latitude(N)`,`Longitude(W)`,`Wind(kts)`, Stage, Landfall, CZ_NAME_STR, DAMAGE_PROPERTY_NUM, DAMAGE_CROPS_NUM, STATE_ABBR, CZ_TIMEZONE, DAMAGE_TOTAL, Year, population, Category, name)

# Edit Column Names:
colnames(Costly_9_Data) <- tolower(colnames(Costly_9_Data))

# Write to file:
write.csv(Costly_9_Data, "Costly_9_Data.csv")
```



###Extra Code (Temporary)
```{r, eval = FALSE}
Hurricane = Hermine #Set hurricane to be analyzed
names(Hurricane)[3:4] = c("Latitude", "Longitude")
Hurricane$Latitude = as.numeric(Hurricane$Latitude)
Hurricane$Longitude = as.numeric(Hurricane$Longitude)
Hurricane = Hurricane %>%
  filter(!is.na(Latitude), !is.na(Longitude))
Hurricane = Hurricane %>%
  mutate(Longitude = -1*Longitude,
         Time = ifelse(Time == "0000", "00:00:00", 
                       ifelse(Time == "0600", "06:00:00",
                              ifelse(Time == "1200", "12:00:00", "18:00:00"))),
         gif_frame = c(1:nrow(Hurricane)),
         isHurricane = Category > 0)
```



#### Link to the Websites Used:
https://www.ncdc.noaa.gov/stormevents/faq.jsp
http://www.nhc.noaa.gov/data/tcr/index.php?season=2005&basin=atl
https://www.ncdc.noaa.gov/stormevents/choosedates.jsp?statefips=17%2CILLINOIS
https://en.wikipedia.org/wiki/List_of_costliest_Atlantic_hurricanes
https://en.wikipedia.org/wiki/Atlantic_hurricane_season
https://factfinder.census.gov/faces/tableservices/jsf/pages/productview.xhtml?src=bkmk (From census.gov)
https://www.census.gov/data/datasets/time-series/demo/popest/intercensal-2000-2010-counties.html
http://www.usinflationcalculator.com/

