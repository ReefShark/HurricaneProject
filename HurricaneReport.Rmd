---
title: "Hurricane Report"
author: "Jerry Chen and Jocelyn Hunyadi"
date: "12/4/2017"
output:
  pdf_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r, echo = FALSE}
# Acquire Necessary R Packages:
require(devtools)
require(RCurl)
require(httr)
require("gganimate")
require(ggmap)
require(stringr)
require(mdsr)
require(tidyverse)
require(mosaic)
require(tidyr)
require(dplyr)
require(readxl)
require(rvest)
require(lubridate)

# Working directory should be the repo folder - add data to the repo folder

```

# Abstract

In the aftermath of the destruction caused by hurricane Harvey, many environmentalists and climate change specialists have suggested a link between global warming and the impact of tropical storms. Since 1980, and perhaps before then, atmospheric co2 levels have increased steadily each year. The goals of this report are, first, to determine if there is a significant relationship between increasing atmospheric co2 levels and hurricane damage and, second, to visually analyze the path of costly hurricanes. After adjusting for inflation, our analyses indicate that co2 is not significantly correlated with an increase in total economic damage per Atlantic hurricane season. Additionally, the paths of 9 of the most costly hurricanes do not suggest a specific path for highly damaging hurricanes, but reveal some interesting deviations from the general path shape.

# Introduction

> What is/are the research question(s)
> Why is this interesting/important?
> What contributions have we made to answer this question?
  > Overview of the Model
  


# Data

## Datasets:

To explore the relationship between gobal warming and the impact of tropical cyclones, we obtained 4 datasets. The first dataset, `CO2_data`, contains the average level of global atmospheric co2 (ppm) for each year from 1980 to 2016. The data was originally obtained as a txt file from the National Oceanographic and Atmostpheric Administration (NOAA). The average global atmospheric co2 for 2017 was also obtained from the NOAA official website. 

The second dataset, `costly_hurr`, includes Atlantic hurricanes that incurred $1 Billion or more in damage to the United States. The original dataset, scraped from Wikipedia, included the following variables: Name (of the hurricane), Damage (in Billions), Storm Classification (at peak intensity), Areas Affected, and References. Peak hurricane category was extracted from the storm classification variable. Additionally, the `CO2_data` dataset was joined to this dataset for analysis by the year.

The third dataset, `seasons_hurr`, includes the total amount of damage costs for each Atlantic hurricane season from 1980 to 2016. This dataset, like the previous, was scraped from Wikipedia and includes the following variables for each year: the number of tropical storms, the number of hurricanes, the number of major hurricanes (Category 3-5), deaths, and damage. Additionally, the `CO2_data` dataset was also joined to this dataset by the year for analysis.

The final dataset is a compilation of hurricane path and damage data for 9 costly Atlantic hurricanes obtained from NOAA in addition to census data by county from the US Census Bureau website. The 9 hurricanes selected are among the Top 11 most costly Atlantic Hurricanes and include: Katrina, Sandy, Ike, Wilma, Ivan, Irene, Charley, Matthew, and Rita. The most costly Atlantic hurricane, Harvey, was not included because data is currently unavailable. Additionally, data for Andrew, the 6th most costly Atlantic hurricane, was limited in comparison to the other hurricanes. Rather than spending additional time wrangling the data for Andrew, we chose to include hurricane Rita instead. The `hurr_9` dataset includes the following variables for each hurricane at each date and time where it was a tropical storm: latitude, longitutde, wind speed (kts), stage, landfall, county, state abbreviation, property damage, crop damage, damage total, timezone, year, population, and category. 

```{r, echo = FALSE}
# Obtain CO2 Data - Found originally in txt file:
CO2_data <- read.csv("CO2_data.csv")
  # Remove excess Column:
CO2_data <- CO2_data[,2:3]
  # Correct column names according to tidy:
colnames(CO2_data) <- c("year","co2")
```

```{r, echo = FALSE}
# Scrape the Data for the Costliest Atlantic Hurricanes from Wikipedia:
url <- 'https://en.wikipedia.org/wiki/List_of_costliest_Atlantic_hurricanes'
list <- url %>%
  read_html() %>%
  html_nodes("table")
  
  # Select the correct table to a dataframe:
costly_hurr <- html_table(list[[1]], fill = TRUE)

  # Join with CO2 Data:
costly_hurr <- left_join(costly_hurr, CO2_data, by = c("Season" = "year"))

  # Modify column names:
colnames(costly_hurr) = c("name","damage","year","classification","area","reference","co2")

# Save Harvey Damage (for later use):
actual_Harvey <- readr::parse_number(substring(costly_hurr$damage[1],2))

# Modifications to the Data:
  # Remove entries with NA in co2 column:
costly_hurr <- costly_hurr %>% filter(!is.na(co2)) %>%
  # Extract numbers from damage column and convert to numeric:
  mutate(damage = readr::parse_number(substring(damage,2)))

  # Remove part of string excess from classification column:
costly_hurr <- costly_hurr %>%
  mutate(classification = substring(classification,12))

  # Add Category variable
costly_hurr <- costly_hurr %>%
  mutate(category = ifelse(classification == "storm", 0, substring(classification,2,2))) %>%
  mutate(category = ifelse(category == "s", 0, readr::parse_number(category))) %>%
  mutate(category_factor = as.factor(category))

```

```{r, echo = FALSE}
# Scrape the Data for each Atlantic Hurricane Season since 1980:
  # Data originally obtained from the following url:
  # https://en.wikipedia.org/wiki/Atlantic_hurricane_season#Number_of_tropical_storms_and_hurricanes_per_season
  # Data was Modified - modified data = Hurricane_Seasons.csv
  # Please See the Appendix to see how data was modified
seasons_hurr <- read_csv("Hurricane_Seasons.csv")
seasons_hurr <- seasons_hurr[,2:10]

  # Join to CO2 Data:
seasons_hurr <- left_join(seasons_hurr, CO2_data, by = c("year" = "year"))
current_season <- seasons_hurr$damage[38]
```

```{r, echo = FALSE}
# Load in Compilation Dataset of Hurricane Path, Damage, and Census Data for the 9 Costly Hurricanes:
hurr_9 <- read_csv("Costly_9_Data.csv")

```

## Univariate Analysis:

Prior to conducting our analysis, we briefly verified the relationship between year and atmospheric co2. As expected, there is a strong, positive relationship between the two variables. Alternatively put, since 1980, Atmospheric co2 has steadily increased to a present value slightly above 400 ppm. 

```{r, echo = FALSE}
# CO2:
ggplot(CO2_data, aes(x = year, y = co2)) + geom_point() + labs(title = "Change in Atmospheric CO2 since 1980", x = "Year", y = "CO2 (ppm)")
```



# Results
> Discuss the incorrect damage data?

> What does model tell you about the research question?
> Interpret coefficients in context/explain relevance

## Linear Regression Model for Average Damage by Costly Atlantic Hurricanes each Season:

```{r, echo = FALSE}
# Looking at AVERAGE damage for hurricanes that occurred in the same year:
costly_hurr_2 <- costly_hurr %>%
  group_by(co2) %>%
  summarise(avg_damage = mean(damage), total_damage = sum(damage), max_damage = max(damage)) %>%
  mutate(sqrt_avg_damage = sqrt(avg_damage), sqrt_max_damage = sqrt(max_damage))

# Fit the model:
mod_avg <- lm(sqrt_avg_damage ~ co2, data = costly_hurr_2)
summary(mod_avg)

# Plot:
ggplot(costly_hurr_2, aes(y = sqrt_avg_damage, x = co2)) + geom_point() + labs(title = "Average Damage by Costly Hurricanes", x = "CO2 (ppm)", y = "Square Root Average Damage (Billions)") + geom_smooth(method = "lm")
```

With `avg_damage` as the response variable, co2 was not a significant predictor. However, when the square root of `damage` was used as the response variable, co2 was a significant predictor (P-value < .05). The model estimates that for every  1 ppm increase in atmospheric co2, the square root of average damageby Atlantic costly hurricanes will increase by .03365 billion dollars. This model appears to suggest that increasing co2 is correlated with an increase in hurricane impact, specifically in the damage caused. However, the model only accounts for 16.44% of the variation in the square root of average damage. 


## Linear Regression Model for Maximum Damage by Costly Atlantic Hurricanes each Season:

```{r, echo = FALSE}
# Looking at MAX damage for costly hurricanes:
mod_max <- lm(sqrt_max_damage ~ co2, data = costly_hurr_2)
summary(mod_max)

ggplot(costly_hurr_2, aes(y = sqrt_max_damage, x = co2)) + geom_point() + labs(title = "Damage by the Most Costly Hurricane", x = "CO2 (ppm)", y = "Sqare Root Max Damage (Billions)") + geom_smooth(method = "lm")
```

Once again, with `max_damage` as the response variable, co2 was not a significant predictor. When the sqre root of `max_damage` was used as the response variable, co2 was a significant predictor (P-value < .05). The model estimates that for every 1 ppm increase in atmospheric co2, the square root of maximum damage by Atlantic costly hurricanes will increase by an estimated .055 billion dollars. This model also appears to suggest that increasing damage is correlated with increasing atmospheric co2. However, once again, the model only accounts for 16.4% of the variation in the square root of maximum damage.


## Linear Regression Model for Total Damage for each Atlantic Hurricane Season 1980-2016:
```{r, echo = FALSE}
# Hurricane Season:
seasons_hurr <- seasons_hurr %>%
  filter(!is.na(co2)) %>%
  mutate(log_damage = log(damage))

  # Model with co2 as sole predictor:
season_mod1 <- lm(log_damage ~ co2, data = seasons_hurr)
summary(season_mod1) # Sig at .05, R = .13

ggplot(seasons_hurr, aes(x = co2, y = log_damage)) + geom_point() + labs(title = "Damage per Hurricane Season 1980 - 2016", x = "CO2 (ppm)", y = "Log Damage") + geom_smooth(method = "lm")

```

 > Insert Commentary.
 
 
## Adjusted Model for Total Damage for each Atlantic Hurricane Season 1980-2016:
```{r, echo = FALSE}
# Baseline Year for Inflation Calculations: 2017
# Adjusted damage values were done using an inflation calculator - see bottom of Appendix for link to the calculator:

# Vector of adjusted damage values:
damage_adjusted <- c(2993483009.71,122110396.04,255609326.42,6438993975.9,156686795,10315831784,128282764.6,195419630.28,14595443786.98,21284629838.71,283086840.09,4527588105.73,4395277975.77,462599813.15,2596452631.58,15052269685.04,5973992351.82,169052523.36,18461893251.53,8735364345.74,1718905923.34,9894391525.42,3564890494.72,5898463043.48,65289306511.38,200816267281.11,611763392.86,3568929594.58,48117518102.4,88530421.33,5124295547.93,20385371900.83,83766623300.26,1598840687.34,241728406.33,760125455.98,16546493643.94,367560000000)

# Convert to a dataframe:
damage_adjusted <- as.data.frame(damage_adjusted)

# Add as a new column to the working Atlantic Season data:
seasons_hurr <- cbind(seasons_hurr, damage_adjusted)

# Add log damage adjusted column:
seasons_hurr <- seasons_hurr %>% 
  mutate(log_damage_adjusted = log(damage_adjusted)) %>%
  # Remove NA entries for co2:
  filter(!is.na(co2))

# Fit the Model:
mod_adj1 <- lm(log_damage_adjusted ~ co2, data = seasons_hurr)
summary(mod_adj1)

# Plot:
ggplot(seasons_hurr, aes(x = co2, y = log_damage_adjusted)) + geom_point() + geom_smooth(method = "lm") + labs(title = "Adjusted Damage Per Hurricane Season 1980-2016", x = "CO2 (ppm)", y = "Adjusted Log Damage")

```

  > Insert Commentary


# Diagnostics

> Full diagnostics of the model
> Predictions

## Models and Predictions for 2017:

```{r}
# Predicting Harvey Damage from Average:
newdata <- data.frame(co2 = 403.38)
  # Must square - y = sqrt_damage:
p1 <- (predict(mod_avg, newdata, interval = "predict"))^2
  # Difference with Upper:
avg_upper_diff <- actual_Harvey - p1[3]; avg_upper_diff # off by 152 billion
  # Difference with Lower:
avg_lower_diff <- actual_Harvey - p1[2]; avg_lower_diff # off by 198.3037 billion
  # Not Very Useful. Also, doesn't quite make as much sense to use the Average.

```

```{r}
# Predicting Harvey Damage from Maximum:
p2 <-(predict(mod_max, newdata, interval = "predict"))^2
  # Difference with Upper:
max_upper_diff <- actual_Harvey - p2[3]; max_upper_diff # off by 94.6 billion
  # Difference with Lower:
max_lower_diff <- actual_Harvey - p2[2]; max_lower_diff # off by 198 billion
  # Actual Fit:
max_actual_diff <- actual_Harvey - p2[1]; max_actual_diff # off by 173.28 billion
  # Better, but still off by a lot.
  
  # Lurking Variables may account for unaccounted for variation in damage.
```

```{r}
# Predicting 2017 Hurricane Season Damage:
p3 <- exp(predict(season_mod1, newdata, interval = "predict")); p3
  # Difference with upper:
season_upper_diff <- current_season - p3[3]; season_upper_diff # Over Predicted.
  # Difference with lower:
season_lower_diff <- current_season - p3[2]; season_lower_diff # Under Predicted
  # Difference with Fit:
season_actual_diff <- current_season - p3[1]; season_actual_diff # Under Predicted
```

## Hurricane Path:
  > Discuss issues with damage - why we didn't add a heat map to the animation
  
  

# Conclusion

> First - remind of question and provide summary of findings
> Second - Discussion of model limitations
  > What can be done to improve the model?
  > What can be done to improve the data?



# Appendix

### Modifications to Hurricane Season Data:
```{r, eval = FALSE}
url <- "https://en.wikipedia.org/wiki/Atlantic_hurricane_season#Number_of_tropical_storms_and_hurricanes_per_season"

list <- url %>%
  read_html() %>%
  html_nodes("table")
  
# Get Data:
names <- c("year","num_trop_storms","num_hurricanes","num_major","deaths","damage")

h_season08 <- html_table(list[[15]], fill = TRUE)
h_season08 <- h_season08[,c(1,3:7)]
colnames(h_season08) <- names

h_season09 <- html_table(list[[16]], fill = TRUE)
h_season09 <- h_season09[,c(1,3:7)]
colnames(h_season09) <- names

h_season10 <- html_table(list[[17]], fill = TRUE)
h_season10 <- h_season10[,c(1,3:7)]
colnames(h_season10) <- names

h_season11 <- html_table(list[[18]], fill = TRUE)
h_season11 <- h_season11[,c(1,3:7)]
colnames(h_season11) <- names

# Join together:
h_season <- rbind(h_season08, h_season09, h_season10, h_season11)

# Remove entries with Unknown damage:
h_season <- h_season %>% filter(damage != "Unknown")

# Remove symbols/words from Damage and multiply by appropriate multiplier column:
h_season <- h_season %>%
  mutate(damage_number = readr::parse_number(str_extract(damage, "[0-9|\\.]+")),
         damage_magnitude = str_extract(damage, "[m|b]illion"),
         damage_magnitude = ifelse(is.na(damage_magnitude), "thousand", damage_magnitude),
         damage = ifelse(damage_magnitude == "thousand", damage_number*1000, 
                         ifelse(damage_magnitude == "million", damage_number*1000000, damage_number*1000000000)))

# Add total storms column:
h_season <- h_season %>% mutate(storms_total = num_trop_storms + num_hurricanes)
```

### Process of Acquiring Path, Damage, and Population Data for the 9 Hurricanes:

Path Data for each Hurricane (listed in the Data section) was contained in a table on a hurricane's report on the NOAA website. PDFtables.com converted the pdf file to an excel file for use. The following code was used for all 9 of the hurricanes, but hurricane Rita will be used as an example.

#### Initial Loading of Path Data:
```{r, eval = FALSE}
# Note: All files were saved in the working directory for this portion:

# Load in the Excel File:
Rita <- read_excel("Rita.xlsx", sheet = 11)

# Temporarily Store certain information:
datelandfall1 <- "24 / 0740"
landfall1 <- "Johnson's Bayou, LA"
  # Note: For Hurricanes with more than one date and location of landfall, there was more than 1 datelandfall and landfall holder

# Remove Extra Rows and Columns:
Rita <- Rita[c(4:38,42),] 
  # The excel files contained extra, misc. information that was unneded
  # Rows selected varied by hurricane

# Change some column names:
name <- c("Date_Time","Latitude(N)","Longitude(W)","Pressure","Wind(kts)","Stage")
colnames(Rita) <- name

```

#### Path Data Clean-up:
```{r, eval = FALSE}
  # Edit Data:
Rita <- Rita %>%
  mutate(Landfall = ifelse(Date_Time == datelandfall1, landfall1, "No"))

# Seperation of Date_Time into Date and Time:
Rita <- Rita %>%
  # Extract individual variables from Date_Time
  mutate(Year = "2005", 
         Time = substring(Date_Time,5,9),
         Day = substring(Date_Time,1,2),
         Month = "9") %>%
  # Join Year, Month, and Day together:
  unite(Date, Year, Month, Day, sep = "-", remove = FALSE) %>%
  # Change Date to Date format:
  mutate(Date = as.Date(Date)) %>%
  select(Date, Time, `Latitude(N)`, `Longitude(W)`, Pressure, `Wind(kts)`, Stage, Landfall)

# Convert Some Columns to Numeric:
Rita <- Rita %>%
  mutate(Time = readr::parse_number(Time),
         `Wind(kts)` = readr::parse_number(`Wind(kts)`),
         `Latitude(N)` = readr::parse_number(`Latitude(N)`),
         `Longitude(W)` = readr::parse_number(`Longitude(W)`))
  
# Obtain the Category Level from Wind Speed:
Rita <- Rita %>%
  mutate(Category = ifelse(`Wind(kts)` < 64, 0, ifelse(`Wind(kts)` >= 62 & `Wind(kts)` <= 82,1,ifelse(`Wind(kts)` >= 83 & `Wind(kts)` <= 95,2,ifelse(`Wind(kts)` >= 96 & `Wind(kts)` <= 113,3,ifelse(`Wind(kts)` >= 114 & `Wind(kts)` <= 135, 4,5))))))
```

The NOAA website has an option to search damage records by text search. Using this method, it is possible to search for specific hurricanes. However, the data provided is not downloadable. It is possible to also search by date and state and obtain data downloadable as a csv. Using the dates of each hurricane and the states known to be affected, damage data was gathered using this method. Once damage data was obtained, it was joined to the path data by date and time. Below is the code for hurricane Rita: 

#### Acquire Damage Data and Cleanup:
```{r, eval = FALSE}
# Example of Loading in a csv file for a state affected by Hurricane Rita:
RitaFlorida <- read_csv("RitaFlorida.csv")

# Bind all Damage Data Together:
RitaDamage <- rbind(RitaPuerto, RitaFlorida, RitaTexas, RitaLouis, RitaMiss, RitaArkansas, RitaTenn, RitaMissouri)

# Change BEGIN_DATE to a Date type:
RitaDamage <- RitaDamage %>%
  mutate(BEGIN_DATE = mdy(BEGIN_DATE))

# Change Time to 0, 600, 1200, 1800 - Based on a determined Range:
  # 0 - 600 --> 0, 600 - 1200 --> 600, 1200 - 1800 --> 1200, 1800
  # Ensures every damage point will match to the Hurricane Data
  # Hurricane data typically only recorded at 0, 600, 1200, 1800
RitaDamage <- RitaDamage %>%
  mutate(BEGIN_TIME = ifelse(BEGIN_TIME >= 0 & BEGIN_TIME < 600, 0, 
                       ifelse(BEGIN_TIME >= 600 & BEGIN_TIME < 1200, 600,
                              ifelse(BEGIN_TIME >= 1200 & BEGIN_TIME < 1800, 1200,
                                     1800))))

```

#### Join Path and Damage Data:
```{r, eval = FALSE}
# Join the Data on Date and Time:
RitaCombined <- left_join(Rita, RitaDamage, by = c("Date" = "BEGIN_DATE", "Time" = "BEGIN_TIME"))

# Total Damage Column:
RitaCombined <- RitaCombined %>% 
  mutate(DAMAGE_TOTAL = DAMAGE_PROPERTY_NUM + DAMAGE_CROPS_NUM)

# Remove NAs from Total Damage:
RitaCombined1 <- RitaCombined %>% filter(!is.na(DAMAGE_TOTAL))
RitaCombined1 <- RitaCombined1 %>% filter(DAMAGE_TOTAL >= 0)

# To ensure the results of this process were not lost, the data was written to a csv file at this time.
write.csv(RitaCombined1, "RitaCombinedData.csv")
```

Census data was downloaded from the US Census Bureau website as two csv files: 1 for 2010-2016 and another for 2000-2010. Below is the process for obtaining census data:

#### Census Data 1: 2010-2016
```{r, eval = FALSE}
# Vector of correct column names:
names <- c("id","id2", "geography", "2010_census","2010_estimate_base","2010_estimate_july","2011","2012","2013","2014","2015","2016")

# Load in the Data:
USA <- read_csv("CensusData/USA1016.csv")
  # Change Column Names
colnames(USA) <- names
  # Remove Excess Row
USA <- USA[2:3143,]

# Seperate Geography into State and County:
USA <- USA %>%
  mutate(state = str_split_fixed(geography, ", ", 2)[,2],
         county = str_split_fixed(geography, ", ", 2)[,1])

# Change columns to numeric:
USA <- USA %>%
  mutate(`2010_census` = readr::parse_number(`2010_census`),
         `2010_estimate_base` = readr::parse_number(`2010_estimate_base`),
         `2010_estimate_july` = readr::parse_number(`2010_estimate_july`),
         `2011` = readr::parse_number(`2011`),
         `2012` = readr::parse_number(`2012`),
         `2013` = readr::parse_number(`2013`),
         `2014` = readr::parse_number(`2014`),
         `2015` = readr::parse_number(`2015`),
         `2016` = readr::parse_number(`2016`))

# Consolidate the 2010 columns into 1 average column:
USA <- USA %>%
  mutate(`2010` = trunc((`2010_census` + `2010_estimate_base` + `2010_estimate_july`)/3))

# Select Columns of importance:
USA <- USA %>% select(id, id2, state, county, `2010`, `2011`, `2012`, `2013`, `2014`, `2015`, `2016`)

# Convert to Tidy Format:
USA_tidy <- gather(USA, key = year, value = population, -id, -id2, -state, -county)

# Save the file for safety:
write.csv(USA_tidy, "USA2010_16_tidy.csv")
```

#### Census Data 2: 2000-2010
```{r, eval = FALSE}
# Vector of correct column names:
names <- c("lev","region","division","state_num","county_num","state","county","2000_base","2000_pop","2001","2002","2003","2004","2005","2006","2007","2008","2009","2010_census","2010_estimate")

# 2010 - 2016:
USA0 <- read_csv("CensusData/USA010.csv")
# Change Column Names:
colnames(USA0) <- names
  # Select only necessary columns:
USA0 <- USA0[,6:18]
  # Remove row for the entire state:
USA0 <- USA0 %>% filter(state != county)

# Consolidate 2000 columns into 1 average column:
USA0 <- USA0 %>%
  mutate(`2000` = (`2000_base` + `2000_pop`)/2)

# Select Columns:
USA0 <- USA0 %>% select(state, county, `2000`,`2001`,`2002`,`2003`,`2004`,`2005`,`2006`,`2007`,`2008`,`2009`)

# Convert to Tidy Format:
USA0_tidy <- gather(USA0, key = year, value = population, -state, -county)

# Write to file for safety:
write.csv(USA0_tidy, "USA2000_10_tidy.csv")
```

The Census data for 2010-2016 was joined to hurricanes that fell within those years. Similarly, the Census data for 2000-2010 was joined to the remaining hurricanes. Census data was joined to each of our 9 hurricanes. Once again, Rita will be used as the example in the code below:

#### Join Path, Damage, and Census Data:
```{r}
# Preparations to the Census Data before Joining:
# 2010-2016 Census Data:
USA_tidy <- read_csv("HurricaneData/USA2010_16_tidy.csv")
  # Remove District of Columbia:
USA_tidy <- USA_tidy %>%
  filter(state != "District of Columbia")
  # Convert state to Abbreviations to match path/damage data: 
for(i in 1:21987) {
  USA_tidy$state[i] = state.abb[grep(USA_tidy$state[i], state.name)]
  i = i + 1
}
  # Set county to lowercase to match path/damage:
USA_tidy <- USA_tidy %>%
  mutate(county = tolower(county))

# 2000-2010 Census Data:
USA0_tidy <- read_csv("HurricaneData/USA2000_10_tidy.csv")
  # Remove District of Columbia:
USA0_tidy <- USA0_tidy %>%
  filter(state != "District of Columbia")
  # Convert state to Abbreviations to match path/damage data:
for(i in 1:31420) {
  USA0_tidy$state[i] = state.abb[grep(USA0_tidy$state[i], state.name)]
  i = i + 1
}
  # Set county to lowercase to match path/damage:
USA0_tidy <- USA0_tidy %>%
  mutate(county = tolower(county))

# Join:
  # Load in if Saved previously or simply use RitaCombined
Rita <- read_csv("HurricaneData/RitaCombinedData.csv")

Rita <- Rita %>%
  mutate(CZ_NAME_STR = tolower(CZ_NAME_STR),
         Year = lubridate::year(Date)) %>%
  # Zones have NA in the BEGIN_LOCATION COLUMN:
  filter(!is.na(BEGIN_LOCATION)) %>%
  # Replace co. with county:
  mutate(CZ_NAME_STR = gsub("co\\.$","county",CZ_NAME_STR)) %>%
  # Remove entries with par. at the end:
  filter(!grepl("par\\.$",CZ_NAME_STR))
  # Combine with Census Data:
Rita_Census_tidy <- left_join(Rita, USA0_tidy, by = c("Year" = "year","CZ_NAME_STR" = "county","STATE_ABBR" = "state"))

# For safety - write to file:
write.csv(Rita_Census_tidy, "Rita_Census_tidy.csv")

```

#### Joining 9 Hurricanes Together:
```{r, eval = FALSE}
# Add Column for Hurricane Name:
Katrina_Census_tidy <- Katrina_Census_tidy %>% mutate(name = "Katrina")
Sandy_Census_tidy <- Sandy_Census_tidy %>% mutate(name = "Sandy")
Ike_Census_tidy <- Ike_Census_tidy %>% mutate(name = "Ike")
Wilma_Census_tidy <- Wilma_Census_tidy %>% mutate(name = "Wilma")
Ivan_Census_tidy <- Ivan_Census_tidy %>% mutate(name = "Ivan")
Irene_Census_tidy <- Irene_Census_tidy %>% mutate(name = "Irene")
Charley_Census_tidy <- Charley_Census_tidy %>% mutate(name = "Charley")
Matthew_Census_tidy <- Matthew_Census_tidy %>% mutate(name = "Matthew")
Rita_Census_tidy <- Rita_Census_tidy %>% mutate(name = "Rita")

# Remove Excess Columns that Remained:
Sandy_Census_tidy <- Sandy_Census_tidy[, c(1:46,49,50)]
Irene_Census_tidy <- Irene_Census_tidy[, c(1:46,49,50)]
Matthew_Census_tidy <- Matthew_Census_tidy[, c(1:46,49,50)]

# Bind together:
Costly_9_Data <- rbind(Katrina_Census_tidy, Sandy_Census_tidy, Ike_Census_tidy, Wilma_Census_tidy, Ivan_Census_tidy, Irene_Census_tidy, Charley_Census_tidy, Matthew_Census_tidy, Rita_Census_tidy) 

# Select Relevant Columns:
Costly_9_Data <- Costly_9_Data %>%
  select(Date, Time, `Latitude(N)`,`Longitude(W)`,`Wind(kts)`, Stage, Landfall, CZ_NAME_STR, DAMAGE_PROPERTY_NUM, DAMAGE_CROPS_NUM, STATE_ABBR, CZ_TIMEZONE, DAMAGE_TOTAL, Year, population, Category, name)

# Edit Column Names:
colnames(Costly_9_Data) <- tolower(colnames(Costly_9_Data))

# Write to file:
write.csv(Costly_9_Data, "Costly_9_Data.csv")
```

#### Creating Animations
## Data Wrangling for Animations
```{r, warning = FALSE}
# Read in data (testing purposes)
Costly_9_Data <- read_csv("Costly_9_Data.csv")

Path_All <- Costly_9_Data
names(Path_All)[4:5] = c("latitude", "longitude")
Path_All <- Path_All %>%
  select(date, time, name, latitude, longitude, `wind(kts)`, category) %>%
  unique() %>%
  filter(!is.na(latitude), !is.na(longitude), !is.na(`wind(kts)`)) %>%
  mutate(isHurricane = ifelse(is.na(category), FALSE,
                              ifelse(category > 0, TRUE, FALSE)),
         longitude = -1*longitude,
         time_long = ifelse(time == 0, "00:00:00", 
                            ifelse(time == 600, "06:00:00",
                                   ifelse(time == 1200, "12:00:00", "18:00:00"))),
         date_time = ymd_hms(paste(as.character(date), time_long), tz = "US/Eastern"))
```

## Creating Individual Hurricane Animations
```{r, warning = FALSE}
hurricanes = unique(Path_All$name)
for (i in 1:9) {
  hurricane_name = hurricanes[i]
  Hurricane_path <- Path_All %>%
    filter(name == hurricane_name, !is.na(latitude), !is.na(longitude), !is.na(`wind(kts)`)) %>%
    arrange(date_time)
  
  map_bbox <- make_bbox(lat = latitude, lon = longitude, data = Hurricane_path) #specify bounds of map
  m <- get_map(location = c(lon = mean(Hurricane_path$longitude), lat = mean(Hurricane_path$latitude)), source = "google", maptype = "terrain", zoom = 4) #create map
  
  #top = max(Hurricane_path$latitude)
  #bottom = min(Hurricane_path$latitude)
  #left = min(Hurricane_path$longitude) - 8
  #right = max(Hurricane_path$longitude) + 8
  
  p <- ggmap(m) + 
    geom_path(aes(x=longitude, y=latitude, cumulative = TRUE, frame = date_time), data=Hurricane_path) +
    geom_point(aes(x=longitude, y=latitude, size = `wind(kts)`, frame = date_time, color = isHurricane), shape = 8, data=Hurricane_path) + 
    scale_color_manual(values=c("slateblue4", "firebrick3"))
    #scale_x_continuous(limits = c(left, right), expand = c(0, 0)) +
    #scale_y_continuous(limits = c(bottom, top), expand = c(0, 0))

  file_location = paste("GIF_output/", hurricane_name, ".gif", sep = "")
  gganimate(p, filename=file_location)
}
```


## Combined GIF: All Hurricanes
```{r}
All = Path_All
year(All$date) = 2017
All$date_time = ymd_hms(paste(as.character(All$date), All$time_long), tz = "US/Eastern")

m <- get_map(location = c(lon = mean(Path_All$longitude), lat = mean(All$latitude)), source = "google", maptype = "terrain", zoom = 4) #create map

p <- ggmap(m) + 
  geom_path(aes(x=longitude, y=latitude, cumulative = TRUE, frame = date_time, color = name), data=All) +
  geom_point(aes(x=longitude, y=latitude, size = `wind(kts)`, frame = date_time, color = name), shape = 8, data=All)

gganimate(p, filename="GIF_output/combined.gif")

# Annotate or change font in ggplot (hurricane symbol)
```

###Extra Code (Temporary)
```{r, eval = FALSE}
Hurricane = Hermine #Set hurricane to be analyzed
names(Hurricane)[3:4] = c("Latitude", "Longitude")
Hurricane$Latitude = as.numeric(Hurricane$Latitude)
Hurricane$Longitude = as.numeric(Hurricane$Longitude)
Hurricane = Hurricane %>%
  filter(!is.na(Latitude), !is.na(Longitude))
Hurricane = Hurricane %>%
  mutate(Longitude = -1*Longitude,
         Time = ifelse(Time == "0000", "00:00:00", 
                       ifelse(Time == "0600", "06:00:00",
                              ifelse(Time == "1200", "12:00:00", "18:00:00"))),
         gif_frame = c(1:nrow(Hurricane)),
         isHurricane = Category > 0)
```



#### Link to the Websites Used:
https://www.ncdc.noaa.gov/stormevents/faq.jsp
http://www.nhc.noaa.gov/data/tcr/index.php?season=2005&basin=atl
https://www.ncdc.noaa.gov/stormevents/choosedates.jsp?statefips=17%2CILLINOIS
https://en.wikipedia.org/wiki/List_of_costliest_Atlantic_hurricanes
https://en.wikipedia.org/wiki/Atlantic_hurricane_season
https://factfinder.census.gov/faces/tableservices/jsf/pages/productview.xhtml?src=bkmk (From census.gov)
https://www.census.gov/data/datasets/time-series/demo/popest/intercensal-2000-2010-counties.html
http://www.usinflationcalculator.com/

